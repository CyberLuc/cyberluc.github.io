---
layout: post
title: "CLRS - Ch2.2 - Analyzing Algorithm"
date: 2013-07-31 22:07
comments: true
keywords: CLRS
description:
categories: CLRS读书笔记
tags: [Algorithm, CLRS]
published: true
---

前面的介绍略过不再记录，直接来看对于Insertion Sort的分析。

### 1.Analysis of insertion sort - 对插入排序的分析
衡量一个算法的好坏，重要的标准之一当然就是解决问题所需的时间的多少了，通常情况下都是希望运行越快越好。而算法的运行时间并不是固定的，它根据输入数据量的大小而变化。所以通常建立一个以输入数据量大小（input size）$$n$$为自变量的函数来表示算法的运行时间（running time）。

<!-- more -->

`Input size`的定义并不是固定不变的，对于前面提到的插入排序来说，$$n$$无非就是数组的大小。对于乘法来说，由于计算机的电子特性，一般用乘数的二进制位数作为衡量。而对于一个图论算法来讲，输入的数据量可能同时由图的节点(Vertices)和边(Edges)两个量组成。

`Running time`在这里暂时被定义为算法对于某一特定输入所需要执行的`操作数量`，或者说是所需执行的`步数`，这就把算法的运行时间和具体的计算机独立了开来，所以并不以算法在某一特定电脑上的运行时间为标准来定义算法的运行时间。


假设每一行的操作都需要花费常数项的时间$$c_i$$，接下来我们就可以来分析一下插入排序了。


其实CLRS这里的定义略显繁琐，比我在《Data Structure and Algorithm Analysis in C》中看到的描述要复杂上一些，因为其书中将每一个基本操作定义为相同的常数项时间（当然其实乘法所需的时间远大于加法），每一行可以含有多个基本操作，比如for循环的那一行就含有一次赋值，一次比较，与一次自增。而CLRS将每一行所需时间定义为一个常数项，那么有多少行就得有多少个常数项。

```c void insertionSort(int A[], int num)
for(i = 2; i <= num; i++){     //c1
    key = A[i];                //c2
    j = i - 1;                 //c3
    while(j>0 && A[j]<key){    //c4
        A[j+1] = A[j];         //c5
        j--;                   //c6
    }
    A[j+1] = key;              //c8
}
```

设$T(n)$为插入排序的运行时间，每行所需时间$c_i$如上所示，另设每一次while循环执行的次数为$t_i$，也即根据$i$的数值而变化。

显然第1行for执行次数为$n$，但循环体内部代码只执行$n-1$次，因为条件判断会比循环体内部代码多执行1次以判断结束条件。所以，第2、3、8行都执行$n-1$次。第四行所需执行的总次数应该为$\sum_{i=2}^{n}t_i$。

和上面for循环同理，每当while执行了$t_i$次时，它的内部代码只执行了$t_i-1$次，所以第5、6行的总执行次数应该均为$\sum_{i=2}^{n}(t_i-1)$。

综上所述：

$$
\begin{equation}
\begin{aligned}
T(n)=c_1n+c_2(n-1)+c_3(n-1)+c_4\sum_{i=2}^{n}t_i+c_5\sum_{i=2}^{n}(t_i-1)+c_6\sum_{i=2}^{n}(t_i-1)+c_8(n-1)
\end{aligned}
\end{equation}
$$

分析算法的时候是根据算法的输入数据量进行的分析，不过就算是同样的数据输入量，输入数据的不同仍旧会造成算法运行时间的天差地别。

就像这里的插入排序，一副已经洗好的从大到小排列的牌是所谓的Best Case，因为已经排好序了，每一次while循环都会在第一次条件判断时中断。所以第1、2、3、8行的执行时间不变，但是第5、6行根本就得不到执行，第4行将总共执行n-1次。

也就是：

$$
\begin{equation}
\begin{aligned}
T(n)&=c_1n+c_2(n-1)+c_3(n-1)+c_4(n-1)+c_8(n-1)\\
&=(c_1+c_2+c_3+c_4+c_8)n+(c_2+c_3+c_4+c_8)
\end{aligned}
\end{equation}
$$

显然这是个一次多项式，是一个线性方程，也把这时候的时间复杂度称为线性复杂度。

而一副从小到大排序的扑克对于这里的插入排序来说，就是一个噩梦了，Worst Case。

对于第4行来说，$t_i$正好等于$i$的值，执行总次数为$\sum_{i=2}^{n}i=\frac{n(n+1)}{2}-1$。

第5、6行的执行总次数为$\sum_{i=2}^{n}(i-1)=\frac{n(n-1)}{2}$。

所以：

$$
\begin{equation}
\begin{aligned}
T(n)&=c_1n+c_2(n-1)+c_3(n-1)+c_4(\frac{n(n+1)}{2}-1)+c_5\frac{n(n-1)}{2}+c_6\frac{n(n-1)}{2}+c_8(n-1)\\
&=(\frac{c_4}{2}+\frac{c_5}{2}+\frac{c_6}{2})n^2+(c_1+c_2+c_3+\frac{c_4}{2}-\frac{c_5}{2}-\frac{c_6}{2}+c_8)n-(c_2+c_3+c_4+c_8)
\end{aligned}
\end{equation}
$$

嗯，挺长的一串的，其实也就是一个二次多项式而已，也把此时的时间复杂度称为平方复杂度。

因为无法预先确定输入数据的质量，所以一般在算法分析中给算法定出一个上限，采用worst case的分析方式。也就是不管输入数据怎么样变化，算法的运行时间总不会超过某个相应的量，只少不多。

Average case的分析方式个人感觉在实际应用中有一定优势，不过书上说这种分析方式比起worst case来说要麻烦太多了，而且对于某些特定问题来说一个”平均“的定义也不是特别的清晰。但是average case对于随机算法来说却是一个很好的分析方法，用概率的方法给出运行时间，比如快速排序算法。

因为比较两个算法时，像上面那样的具体分析往往是不必要的，所以一般用算法运行时间的增长率为标准判断算法优劣。前面插入排序的worst case运行时间就是$Θ(n^2)$。

--未完待续--
